
# Image Captioning
 
This is a re-implementation of the Object Relation Transformer published in NeurIPS 2019. You can find the paper [here](https://proceedings.neurips.cc/paper_files/paper/2019/file/680390c55bbd9ce416d1d69a9ab4760d-Paper.pdf).

The Object Relation Transformer (ORT) is a deep learning model designed to improve object detection and recognition by focusing on contextual relationships between objects in an image.

In simpler words : -  Instead of just recognizing a person and a bike separately, it understands whether the person is riding the bike or just standing next to it. It does this by paying attention to how objects interact, making object detection smarter and more accurate.

## DATASET
The research paper uses MS-COCO dataset but for our convience we have used [Flickr 8k Dataset](https://www.kaggle.com/datasets/adityajn105/flickr8k)

This dataset includes 8,000 images from Flickr, 5 captions per image, written by humans, captions describe whatâ€™s happening in the image.


